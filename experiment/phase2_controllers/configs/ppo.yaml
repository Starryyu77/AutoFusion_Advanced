controller:
  action_dim: 16
  algorithm: ppo
  baseline_momentum: 0.9
  clip_range: 0.2
  disable_early_stop: true
  early_stop_patience: 50
  entropy_coef: 0.01
  hidden_dim: 256
  learning_rate: 3e-5
  max_iterations: 100
  reward_weights:
    accuracy: 1.0
    compile_success: 2.0
    efficiency: 0.5
  state_dim: 64
  use_critic: false
evaluator:
  batch_size: 8
  num_evals: 3
  quick_train_epochs: 10
  type: sandbox
  use_lr_decay: true
experiment:
  name: controller_ppo
  output_dir: results/phase2_controllers/ppo
generator:
  max_tokens: 4096
  model: deepseek-chat
  strategy: cot
  temperature: 0.7
reward:
  alpha: 3.0
  baseline: 2.5
  label_smoothing: true
  max_sharpened: 10.0
  type: exponential
  weights:
    accuracy: 1.0
    compile_success: 2.0
    efficiency: 0.5
